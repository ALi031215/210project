---
title: "Predicting NBA Rookie Success from College Performance"
author: "Muhammad Shah, Alex Li"
date: "2024-04-25"
---

```{r setup, include=FALSE}

library(Metrics)
library(tidyverse)
library(caret)
library(ggplot2)
```

## Introduction

Predictive modeling of NBA rookie success based on college performance statistics provides crucial insights for sports analytics. This analysis utilizes historical data to establish relationships between collegiate achievements and professional performance in the NBA, thereby supporting decision-making in sports management.

### Research Question

How can NBA rookie success, measured by points per game, be predicted from their college basketball statistics? This study employs statistical modeling techniques to forecast NBA outcomes from detailed collegiate performance metrics.

### Data Description

This study employs two primary datasets:

1. **College Basketball Dataset**: Consists of detailed player statistics from NCAA college basketball spanning 2009 to 2021. This dataset includes metrics such as player efficiency ratings and scoring averages. 

[Source: https://www.kaggle.com/datasets/adityak2003/college-basketball-players-20092021/data]

2. **NBA Player Statistics**: Contains performance data for NBA rookies' first season from 2009 to 2021, focusing on points per game and efficiency metrics. 

[Source: https://www.kaggle.com/datasets/raunakpandey030/nba-player-stats]

### Key Variables:
- `College_points`: Average points scored per game in the player's final college season.
- `eFG%`: Effective field goal percentage in college.
- `TS%`: True shooting percentage in college.
- `NBA_points`: Average points per game during the player's rookie NBA season.

### Data Cleaning and Merging Process
The data was meticulously cleaned to ensure consistency and relevance to the study's goals. This involved:
- Renaming columns for clarity.
- Filtering records to retain only the last year of college and the first year in the NBA to focus on the transition period.
- Removing duplicate entries and normalizing data formats for accurate merging.


```{r load, echo=FALSE}
# Load libs
library(dplyr)
library(readr)
library(stringr)

# Reading and processing the college data
college <- read_csv("CollegeBasketballPlayers2009-2021.csv") %>%
  mutate(year = as.character(year)) %>%
  rename(College_points = pts) %>%
  arrange(desc(year)) %>%
  distinct(player_name, .keep_all = TRUE) %>%
  select(player_name, eFG, conf, TS_per, College_points, year)

# Reading and processing the NBA data
nba <- read_csv("NBA_Player_Stats.csv") %>%
  mutate(Year = as.character(Year),
         Year = str_split(Year, '-', simplify = TRUE)[, 1]) %>%
  arrange(Year) %>%
  rename(NBA_points = PTS,
         player_name = Player) %>%
  distinct(player_name, .keep_all = TRUE) %>%
  select(player_name, NBA_points)

# merging
merged_points <- inner_join(college, nba, by = "player_name")
```

### Exploratory Data Analysis

```{r eda, echo=FALSE}

# 1. Relationship between College Points and NBA Points with Linear Model Fit
ggplot(merged_points, aes(x = College_points, y = NBA_points)) +
  geom_point(aes(color = conf), alpha = 0.6) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relationship between College Points and NBA Rookie Points",
       subtitle = "Each point represents a player; colored by conference",
       x = "College Points per Game", y = "NBA Points per Game") +
  theme_minimal()

# 2. Explore the efficiency (eFG% and TS%) and its impact on NBA Points
ggplot(merged_points, aes(x = eFG, y = NBA_points)) +
  geom_point(aes(color = conf), alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Effect of College Effective Field Goal Percentage on NBA Points",
       subtitle = "Linear model fit shown in blue",
       x = "Effective Field Goal Percentage", y = "NBA Points per Game") +
  theme_minimal()

ggplot(merged_points, aes(x = TS_per, y = NBA_points)) +
  geom_point(aes(color = conf), alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "green") +
  labs(title = "Impact of College True Shooting Percentage on NBA Points",
       subtitle = "Linear model fit shown in green",
       x = "True Shooting Percentage", y = "NBA Points per Game") +
  theme_minimal()
```

The exploratory data analysis aims to correlate college performance metrics with NBA rookie success, focusing on points per game through visualizations that underscore data distribution and trends.

Relationship between College Points and NBA Rookie Points:
This analysis begins with a scatter plot displaying the relationship between college scoring averages and NBA rookie points. Each data point represents a player, colored by their college conference, overlayed with a linear regression line. The plot suggests a positive correlation between college and NBA scoring, though variability is high. This variability may reflect differences in playing style, player roles, or other factors affecting a player’s transition from college to the NBA.

Effect of College Effective Field Goal Percentage on NBA Points:
A second plot examines how college effective field goal percentage (eFG%) relates to NBA points. A linear fit indicates a modest positive correlation, implying that higher eFG% in college might predict better NBA performance. However, the relationship is not definitive, suggesting that eFG% may not fully predict NBA success without considering other contextual factors like the player's role and gameplay system.

Impact of College True Shooting Percentage on NBA Points:
The final plot explores the relationship between college true shooting percentage (TS%) and NBA rookie points. The positive trend shown by the green regression line suggests that TS%, which accounts for overall shooting efficiency including 3-pointers and free throws, might be a slightly better predictor of NBA success than eFG% alone.

## Methodology

### Model Selection Process

In this study, we aimed to predict NBA rookie success, quantified by points per game, using their college basketball statistics. Given the continuous nature of our response variable, we considered regression models, which are well-suited for predicting quantitative outcomes. We selected two types of models for our analysis:

**Linear Regression**: Chosen for its simplicity, interpretability, and widespread use in predictive analytics. Linear regression is particularly useful in understanding the direct relationship between each predictor variable and the response variable, providing clear insights into how each college performance metric might influence NBA success.

**Multilayer Perceptron (MLP) Regressor**: Selected for its ability to model nonlinear relationships and interactions between predictors that linear regression might not capture. This model type is part of the neural networks family, offering the flexibility to learn complex patterns in the data, potentially leading to more accurate predictions.

### Predictor Variables
The predictor variables initially included were:
- `eFG%` (Effective Field Goal Percentage)
- `TS%` (True Shooting Percentage)
- `College_points` (Average points per game during the player's final college season)

These variables were chosen due to their direct relationship with scoring performance, which is our primary measure of NBA success.

### Data Splitting
The data was split into training and test sets with a 70-30 ratio, using a random seed for reproducibility (`random_state=999`). This split was chosen to provide a substantial training set for model development while leaving a sizable portion of data for testing model validity.

```{r splitting, echo=FALSE}

set.seed(999)
training_indices <- createDataPartition(merged_points$NBA_points, p = 0.7, list = FALSE)
train_data <- merged_points[training_indices, ]
test_data <- merged_points[-training_indices, ]
```

### Model Enhancement with One-Hot Encoding
To improve the model’s performance, we introduced a categorical variable:
- `conf` (Conference): This variable represents the college conference of each player, which could have an influence on the player's transition to the NBA due to varying levels of competition across conferences.

One-hot encoding was applied to this categorical variable to convert it into a numerical format that could be used in our regression models. This allowed us to examine the impact of different conferences on NBA success.
```{r onehot, echo=FALSE}

# One-hot encoding for the 'conf' variable
train_data <- model.matrix(~ conf - 1, data = train_data) %>% as.data.frame() %>%
  bind_cols(train_data[, c("eFG", "TS_per", "College_points", "NBA_points")])

test_data <- model.matrix(~ conf - 1, data = test_data) %>% as.data.frame() %>%
  bind_cols(test_data[, c("eFG", "TS_per", "College_points", "NBA_points")])

```


### Model Fitting and Diagnostics
Each model was trained using the respective fitting functions in R:

The Linear Regression model was fitted using the lm() function.
The MLP model was fitted using the nnet() package, with specifications for the hidden layer structure and regularization to prevent overfitting.

```{r modelfitting, echo=FALSE}

linear_model <- lm(NBA_points ~ eFG + TS_per + College_points, data = train_data)
summary(linear_model)

# Load the required library
library(nnet)

# Fit an MLP model using the nnet function for regression, with reduced verbosity
mlp_model <- nnet(NBA_points ~ eFG + TS_per + College_points, 
                  data = train_data, 
                  size = 5,        # Number of units in the hidden layer
                  decay = 0.1,     # Weight decay for regularization
                  maxit = 200,     # Maximum number of iterations
                  linout = TRUE,   # Linear output activation function
                  trace = FALSE)   # Set trace to FALSE to reduce output verbosity

summary(mlp_model)
```
### Model Diagnostics

Residual Analysis: Residual plots were examined for patterns that might suggest inadequacies in the model forms. For the linear model, residuals were checked for homoscedasticity and normality.

Shapiro-Wilk Test: Conducted to test the normality of residuals in the linear regression model, where a significant result (p < 2.2e-16) suggested deviations from normality, indicating potential issues with underlying assumptions.

Performance Metrics: Mean Squared Error (MSE) and R-squared were calculated for both models to assess their accuracy and explanatory power.

```{r evalmetrics, echo=FALSE}

# Residual plot for Linear Model
plot(residuals(linear_model), type = 'p', main = "Residual Plot for Linear Model")

# Checking normality of residuals
shapiro.test(residuals(linear_model))

# Linear model evaluation
predictions_lm <- predict(linear_model, newdata = test_data)
mse_lm <- mse(test_data$NBA_points, predictions_lm)  # Fixing the use of test_y
r2_lm <- R2(predictions_lm, test_data$NBA_points)     # Fixing the use of test_y

# MLP model evaluation
predictions_mlp <- predict(mlp_model, newdata = test_data, type = "raw")
mse_mlp <- mse(test_data$NBA_points, predictions_mlp)  # Fixing the use of test_y
r2_mlp <- R2(predictions_mlp, test_data$NBA_points)     # Fixing the use of test_y

model_performance <- data.frame(
  Model = c("Linear Regression", "MLP Regressor"),
  MSE = c(mse_lm, mse_mlp),
  R2 = c(r2_lm, r2_mlp)
)

# Print the performance table
print(model_performance)

```
### Consideration of Model Violations

The low R-squared value from the linear model suggested limited explanatory power, prompting further exploration with the MLP model. Despite improved flexibility in capturing non-linear relationships with the MLP, the complexity did not substantially increase the explanatory power as reflected in the metrics. This suggests that further model tuning or alternative modeling approaches might be necessary to enhance predictive performance.

## Results

We deployed two models: Linear Regression and Multilayer Perceptron (MLP) Regressor. The analysis presented here focuses on the output of these models, particularly examining how well they address the research questions through their predictive capabilities.

### Model Performance Metrics

```{r final, echo=FALSE}

# Load necessary libraries
library(ModelMetrics)  # For mse and r2_score

# Assume merged_points is already in your environment
set.seed(999)
training_indices <- createDataPartition(merged_points$NBA_points, p = 0.7, list = FALSE)
train_data <- merged_points[training_indices, ]
test_data <- merged_points[-training_indices, ]

# Prepare data for modeling
train_x <- train_data[, c("eFG", "TS_per", "College_points")]
train_y <- train_data$NBA_points
test_x <- test_data[, c("eFG", "TS_per", "College_points")]
test_y <- test_data$NBA_points


linear_model <- lm(NBA_points ~ eFG + TS_per + College_points, data = train_data)
summary(linear_model)

# Predictions and model evaluation
predictions_lm <- predict(linear_model, newdata = test_data)
mse_lm <- mse(test_y, predictions_lm)
r2_lm <- R2(predictions_lm, test_y)
print(paste("Linear Model Test MSE:", mse_lm))
print(paste("Linear Model Test R2:", r2_lm))

```

The evaluation of our models' performance is based on two primary statistics: Mean Squared Error (MSE) and R-squared (R²), which provide insight into the models' accuracy and the proportion of variance in NBA points they explain.
***Linear Regression Model:***
MSE: 13.55590
R²: 0.01200178
***MLP Regressor:***
MSE: 14.38812
R²: 0.02530211

These metrics indicate a relatively low explanatory power for both models, highlighting the challenges in using collegiate performance alone to predict NBA success.

### Visual Assessment of Model Predictions
```{r plotting models, echo=FALSE}

# Creating a data frame for plotting
actual_vs_predicted_lm <- data.frame(
  Actual = test_data$NBA_points,
  Predicted = predictions_lm,
  Model = 'Linear Regression'
)

actual_vs_predicted_mlp <- data.frame(
  Actual = test_data$NBA_points,
  Predicted = predictions_mlp,
  Model = 'MLP Regressor'
)

# Combining both data frames
all_predictions <- rbind(actual_vs_predicted_lm, actual_vs_predicted_mlp)

# Plotting Actual vs Predicted Values for Both Models
ggplot(all_predictions, aes(x = Actual, y = Predicted, color = Model)) +
  geom_point(alpha = 0.5) +  # Using semi-transparent points
  geom_smooth(method = "lm", se = FALSE, color = "black") +  # Adding a regression line without confidence interval
  facet_wrap(~ Model) +  # Separate plots for each model
  labs(title = "Actual vs Predicted NBA Points",
       x = "Actual NBA Points per Game",
       y = "Predicted NBA Points per Game") +
  theme_minimal() +
  scale_color_manual(values = c("blue", "green"))  # Custom colors for each model
```

To visually assess model performance, we plotted the actual versus predicted NBA points for both models:

The Linear Regression model shows a clustering of predictions around the lower range of NBA points, indicating limited predictive variability and a tendency to underpredict the performance of higher-scoring rookies.
The MLP Regressor exhibits greater spread in predictions, suggesting it captures more complexity in the data. However, the spread includes significant prediction errors, as evident from points far from the line of perfect prediction.
This visual comparison underscores the models' struggles to accurately predict NBA rookie points and suggests potential areas for model refinement.

### Interpretation of Key Results
The coefficients from the Linear Regression model provide a quantitative measure of how each predictor influences NBA rookie success:

College Points: The positive coefficient (0.10153, p-value = 0.0032) implies that higher scores in college predict higher NBA rookie scores, validating the hypothesis that college scoring prowess translates to professional success to some extent.
Effective Field Goal Percentage (eFG%) and True Shooting Percentage (TS%): These variables did not show significant predictive power in the model, suggesting that shooting efficiency in college may not directly correlate with NBA success, possibly due to differences in game pace, defensive intensity, and other professional factors.

## Discussion

### Summary of Findings

Our study aimed to predict NBA rookie success from college basketball statistics, focusing on points per game as a key indicator of performance. The analysis utilized linear regression and multilayer perceptron (MLP) models to determine the predictive power of college points per game, effective field goal percentage (eFG%), and true shooting percentage (TS%). The results highlighted that while college points had a statistically significant positive impact on NBA rookie points, the shooting percentages did not show strong predictive power. This suggests that while scoring ability in college can be a predictor of scoring in the NBA, factors measured by eFG% and TS% in college settings do not translate directly to professional success.

### Limitations

One major limitation of our study is the potential for overfitting, especially with the MLP model, which could compromise the generalizability of our findings. The models demonstrated low R² values, indicating they captured only a small fraction of the variance in rookie NBA points. This could be due to the complexity of NBA success, which is influenced by a myriad of factors beyond collegiate statistical performance such as physical attributes, psychological factors, and team dynamics.

The dataset's scope could also limit the analysis. For instance, the dataset includes only players who made it to the NBA, potentially omitting college players who did not progress to professional basketball. This selection bias might distort the relationship between college statistics and NBA success.

### Reliability and Validity

While the data sources are reliable, being derived from comprehensive sports statistics databases, the validity of the conclusions might still be affected by the aforementioned selection bias and the exclusion of variables such as player injuries, mid-season trades, and changes in team strategy. These factors are crucial for a holistic assessment of a player’s performance but were not available in the datasets used.

### Future Work

To enhance the robustness of future models, it would be beneficial to incorporate additional predictors such as player age at draft, physical measurements (e.g., height, wingspan), and perhaps more nuanced metrics of player efficiency and defensive contributions. Including data on player development over their first few NBA seasons could also help in understanding how college performance correlates with long-term professional success.

Advanced modeling techniques could also be explored. For instance, ensemble methods like random forests or boosted trees might capture complex nonlinear relationships more effectively than MLPs or linear models. Furthermore, incorporating player tracking data, which includes detailed movement data during games, could provide deeper insights into how college performance translates into NBA contexts.

Future studies should also consider integrating qualitative assessments such as scouting reports to complement the quantitative analysis. Comparisons with existing literature on predictors of sports performance would help in contextualizing the findings within broader sports analytics research.



